{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('../../Data/train.csv',usecols=[0,4,8,9,10,11,13,14])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use restricted dataset here ( for the last submission) only lines with context_type in [1,5,20,23], because test set only contains these 4 context_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = dataset[dataset['context_type'].isin([1,5,20,23])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1815738, 8)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OBSOLETE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtrain,xtest,ytrain,ytest = train_test_split(dataset.iloc[:,:14],dataset['is_listened'],test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "historical_meantarget_genre = pd.concat([xtrain,ytrain],axis=1).groupby(['user_id','genre_id'],as_index=False)['is_listened'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hist_nb_genre = pd.concat([xtrain,ytrain],axis=1).groupby(['user_id','genre_id'],as_index=False)['is_listened'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "historical_meantarget_genre.columns = ['user_id','genre_id','mean_islistened']\n",
    "hist_nb_genre.columns = ['user_id','genre_id','count_islistened']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xtrain = xtrain.merge(historical_meantarget_genre,how='left',on=['user_id','genre_id'])\n",
    "xtest = xtest.merge(historical_meantarget_genre,how='left',on=['user_id','genre_id'])\n",
    "\n",
    "xtrain = xtrain.merge(hist_nb_genre,how='left',on=['user_id','genre_id'])\n",
    "xtest = xtest.merge(hist_nb_genre,how='left',on=['user_id','genre_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtest.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = ['user_age','context_type','genre_id','listen_type',\n",
    "            'media_duration','user_gender','release_date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FIN OBSOLETE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full data model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici on a d'abord chargé toute la donnée pour calculer une moyenne et un count de is_listened pour chaque user et chaque genre, ces features font overfitté à max mais ça me paraît logique de considérer les actions antérieures de chaque utilisateur face à un genre particulier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hist_mean_islistened = dataset.groupby(['user_id','genre_id'],as_index=False)['is_listened'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hist_nb_islistened = dataset.groupby(['user_id','genre_id'],as_index=False)['is_listened'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hist_mean_islistened.columns = ['user_id','genre_id','mean_islistened']\n",
    "hist_nb_islistened.columns = ['user_id','genre_id','count_islistened']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hist_mean_islistened.to_csv('hist_mean.csv',sep=',',index=False)\n",
    "hist_nb_islistened.to_csv('hist_nb.csv',sep=',',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load hist_mean and hist_nb computed on the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hist_mean_islistened = pd.read_csv('hist_mean.csv',sep=',')\n",
    "hist_nb_islistened = pd.read_csv('hist_nb.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = dataset.merge(hist_mean_islistened,how='left',on=['user_id','genre_id'])\n",
    "dataset = dataset.merge(hist_nb_islistened,how='left',on=['user_id','genre_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1815738, 10)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "release_year n'apportait au final pas de gain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_year(x):\n",
    "    return int(str(x)[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset['release_year'] = dataset['release_date'].apply(lambda x : extract_year(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_age</th>\n",
       "      <th>context_type</th>\n",
       "      <th>genre_id</th>\n",
       "      <th>listen_type</th>\n",
       "      <th>media_duration</th>\n",
       "      <th>user_gender</th>\n",
       "      <th>release_date</th>\n",
       "      <th>user_id</th>\n",
       "      <th>is_listened</th>\n",
       "      <th>mean_islistened</th>\n",
       "      <th>count_islistened</th>\n",
       "      <th>release_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1.000000e+06</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>24.008044</td>\n",
       "      <td>2.262265</td>\n",
       "      <td>1942.898121</td>\n",
       "      <td>0.282579</td>\n",
       "      <td>232.683345</td>\n",
       "      <td>0.384134</td>\n",
       "      <td>2.011225e+07</td>\n",
       "      <td>4217.182774</td>\n",
       "      <td>0.692703</td>\n",
       "      <td>0.692703</td>\n",
       "      <td>74.317344</td>\n",
       "      <td>2011.148507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.822657</td>\n",
       "      <td>4.473217</td>\n",
       "      <td>13096.110213</td>\n",
       "      <td>0.450254</td>\n",
       "      <td>66.248591</td>\n",
       "      <td>0.486390</td>\n",
       "      <td>8.858665e+04</td>\n",
       "      <td>4068.074329</td>\n",
       "      <td>0.461374</td>\n",
       "      <td>0.281999</td>\n",
       "      <td>118.162162</td>\n",
       "      <td>8.859443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.912121e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1912.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>196.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.010010e+07</td>\n",
       "      <td>952.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>226.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.015062e+07</td>\n",
       "      <td>2899.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.016082e+07</td>\n",
       "      <td>6376.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>2016.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>255191.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8216.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.017031e+07</td>\n",
       "      <td>19916.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1145.000000</td>\n",
       "      <td>2017.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             user_age    context_type        genre_id     listen_type  \\\n",
       "count  1000000.000000  1000000.000000  1000000.000000  1000000.000000   \n",
       "mean        24.008044        2.262265     1942.898121        0.282579   \n",
       "std          3.822657        4.473217    13096.110213        0.450254   \n",
       "min         18.000000        0.000000        0.000000        0.000000   \n",
       "25%         21.000000        0.000000        0.000000        0.000000   \n",
       "50%         24.000000        1.000000        0.000000        0.000000   \n",
       "75%         27.000000        2.000000       25.000000        1.000000   \n",
       "max         30.000000       71.000000   255191.000000        1.000000   \n",
       "\n",
       "       media_duration     user_gender  release_date         user_id  \\\n",
       "count  1000000.000000  1000000.000000  1.000000e+06  1000000.000000   \n",
       "mean       232.683345        0.384134  2.011225e+07     4217.182774   \n",
       "std         66.248591        0.486390  8.858665e+04     4068.074329   \n",
       "min          0.000000        0.000000  1.912121e+07        0.000000   \n",
       "25%        196.000000        0.000000  2.010010e+07      952.000000   \n",
       "50%        226.000000        0.000000  2.015062e+07     2899.000000   \n",
       "75%        256.000000        1.000000  2.016082e+07     6376.000000   \n",
       "max       8216.000000        1.000000  2.017031e+07    19916.000000   \n",
       "\n",
       "          is_listened  mean_islistened  count_islistened    release_year  \n",
       "count  1000000.000000   1000000.000000    1000000.000000  1000000.000000  \n",
       "mean         0.692703         0.692703         74.317344     2011.148507  \n",
       "std          0.461374         0.281999        118.162162        8.859443  \n",
       "min          0.000000         0.000000          1.000000     1912.000000  \n",
       "25%          0.000000         0.516129          9.000000     2010.000000  \n",
       "50%          1.000000         0.764706         31.000000     2015.000000  \n",
       "75%          1.000000         0.925926         89.000000     2016.000000  \n",
       "max          1.000000         1.000000       1145.000000     2017.000000  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concat data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "listen = pd.get_dummies(dataset['listen_type'],prefix='listentype')\n",
    "user = pd.get_dummies(dataset['user_gender'],prefix='sex')\n",
    "context = pd.get_dummies(dataset['context_type'],prefix='context')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = pd.concat([dataset,listen,user,context],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1815738, 18)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OBSOLETE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'genre_id', u'context_type', u'media_duration', u'listen_type',\n",
       "       u'user_gender', u'user_id', u'user_age', u'is_listened',\n",
       "       u'mean_islistened', u'count_islistened', u'listentype_0',\n",
       "       u'listentype_1', u'sex_0', u'sex_1', u'context_1', u'context_5',\n",
       "       u'context_20', u'context_23'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = []\n",
    "for i in range(5):\n",
    "    xtrain,xtest,ytrain,ytest = train_test_split(dataset[features],dataset['is_listened'],test_size=0.3)\n",
    "    logit = LogisticRegression()\n",
    "    logit.fit(xtrain,ytrain)\n",
    "    res.append(roc_auc_score(ytest,logit.predict_proba(xtest[features])[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.62868473384245949,\n",
       " 0.62766125616011292,\n",
       " 0.62941162817366347,\n",
       " 0.62982110942170411,\n",
       " 0.62887378081645884]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FIN OBSOLETE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deux modèles, \n",
    "* le premier pour les cas où on dispose d'un historique mean et count is_listened pour l'utilisateur et le genre du test set (features_with)\n",
    "* le deuxième pour les cas où on a pas d'histo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler_with = StandardScaler(copy=True)\n",
    "scaler_without = StandardScaler(copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_with = ['user_age','media_duration','mean_islistened','count_islistened']  + dataset.columns.tolist()[10:]\n",
    "features_without = ['user_age','media_duration']  + dataset.columns.tolist()[10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_fin_with = LogisticRegression()\n",
    "logit_fin_with.fit(scaler_with.fit_transform(dataset[features_with]),dataset['is_listened'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_fin_without = LogisticRegression()\n",
    "logit_fin_without.fit(scaler_without.fit_transform(dataset[features_without]),dataset['is_listened'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prend énormément de temps si dataset gros "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gb = GradientBoostingClassifier(n_estimators=100,max_depth=6)\n",
    "gb.fit(scaler.fit_transform(dataset[features]),dataset['is_listened'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "roc_auc_score(dataset['is_listened'],gb.predict_proba(scaler.transform(dataset[features]))[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction for test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_data = pd.read_csv('../Data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub_data = sub_data.merge(hist_mean_islistened,how='left',on=['user_id','genre_id'])\n",
    "sub_data = sub_data.merge(hist_nb_islistened,how='left',on=['user_id','genre_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "listen_sub = pd.get_dummies(sub_data['listen_type'],prefix='listentype')\n",
    "user_sub = pd.get_dummies(sub_data['user_gender'],prefix='sex')\n",
    "context_sub = pd.get_dummies(sub_data['context_type'],prefix='context')\n",
    "sub_data = pd.concat([sub_data,listen_sub,user_sub,context_sub],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into two parts depending on whether field mean and count_islistened are NA or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub_data_with = sub_data[pd.isnull(sub_data).any(axis=1)==False].reset_index(drop=True)\n",
    "sub_data_without = sub_data[pd.isnull(sub_data).any(axis=1)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>genre_id</th>\n",
       "      <th>ts_listen</th>\n",
       "      <th>media_id</th>\n",
       "      <th>album_id</th>\n",
       "      <th>context_type</th>\n",
       "      <th>release_date</th>\n",
       "      <th>platform_name</th>\n",
       "      <th>platform_family</th>\n",
       "      <th>media_duration</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_islistened</th>\n",
       "      <th>count_islistened</th>\n",
       "      <th>listentype_0</th>\n",
       "      <th>listentype_1</th>\n",
       "      <th>sex_0</th>\n",
       "      <th>sex_1</th>\n",
       "      <th>context_1</th>\n",
       "      <th>context_5</th>\n",
       "      <th>context_20</th>\n",
       "      <th>context_23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2744</td>\n",
       "      <td>1479317140</td>\n",
       "      <td>876497</td>\n",
       "      <td>99692</td>\n",
       "      <td>1</td>\n",
       "      <td>19851231</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>307</td>\n",
       "      <td>...</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2744</td>\n",
       "      <td>1479546361</td>\n",
       "      <td>876497</td>\n",
       "      <td>99692</td>\n",
       "      <td>1</td>\n",
       "      <td>19851231</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>307</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2744</td>\n",
       "      <td>1478457729</td>\n",
       "      <td>876500</td>\n",
       "      <td>99692</td>\n",
       "      <td>1</td>\n",
       "      <td>19851231</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>265</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2744</td>\n",
       "      <td>1480448560</td>\n",
       "      <td>876504</td>\n",
       "      <td>99692</td>\n",
       "      <td>1</td>\n",
       "      <td>19851231</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>356</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2744</td>\n",
       "      <td>1479410530</td>\n",
       "      <td>876497</td>\n",
       "      <td>99692</td>\n",
       "      <td>1</td>\n",
       "      <td>19851231</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>307</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample_id  genre_id   ts_listen  media_id  album_id  context_type  \\\n",
       "0          1      2744  1479317140    876497     99692             1   \n",
       "1          2      2744  1479546361    876497     99692             1   \n",
       "2          3      2744  1478457729    876500     99692             1   \n",
       "3          4      2744  1480448560    876504     99692             1   \n",
       "4          5      2744  1479410530    876497     99692             1   \n",
       "\n",
       "   release_date  platform_name  platform_family  media_duration     ...      \\\n",
       "0      19851231              0                0             307     ...       \n",
       "1      19851231              0                0             307     ...       \n",
       "2      19851231              2                1             265     ...       \n",
       "3      19851231              2                1             356     ...       \n",
       "4      19851231              0                0             307     ...       \n",
       "\n",
       "   mean_islistened  count_islistened  listentype_0  listentype_1  sex_0  \\\n",
       "0         0.875000               8.0             0             1      1   \n",
       "1         0.000000               1.0             0             1      1   \n",
       "2         0.666667               6.0             0             1      1   \n",
       "3         1.000000              28.0             0             1      1   \n",
       "4         0.125000              16.0             0             1      1   \n",
       "\n",
       "   sex_1  context_1  context_5  context_20  context_23  \n",
       "0      0          1          0           0           0  \n",
       "1      0          1          0           0           0  \n",
       "2      0          1          0           0           0  \n",
       "3      0          1          0           0           0  \n",
       "4      0          1          0           0           0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_data_with.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_with = pd.concat([sub_data_with['sample_id'],\n",
    "                      pd.DataFrame(logit_fin_with.predict_proba(scaler_with.transform(sub_data_with[features_with]))[:,1])]\n",
    "                      ,axis=1)\n",
    "pred_without = pd.concat([sub_data_without['sample_id'],\n",
    "                        pd.DataFrame(logit_fin_without.predict_proba(scaler_without.transform(sub_data_without[features_without]))[:,1])]\n",
    "                         ,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.concat([pred_with,pred_without],axis=0)\n",
    "submission.columns = ['sample_id','is_listened']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:1: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "submission.sort(['sample_id'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv('5_twomodels_scaled.csv',index=False,sep=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
